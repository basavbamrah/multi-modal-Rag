{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Modal RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 3 ways to create multi-modal-rag\n",
    "1. Use a multi-modal embedding model like CLIP or imagebind to create embedding  of images and text. REtrieve bith using similarity search and pass the documents toa multi-modal LLM\n",
    "2. Use a multi-modal model to create summarues of images. Retrieve the summarues from vector storage and pass them to an llm for Q&A\n",
    "3. Use a multi-modal LLM to fer description of images. Embed the text description using any embedding model of choice and store original document in doc store Retrieve summarues with a reference to the original image and text chunks. Pass the original document to a multi-modal LLM for answer generation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](https://av-eks-lekhak.s3.amazonaws.com/media/__sized__/article_images/mm-rag-thumbnail_webp-600x300.webp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !sudo apt install tesseract-ocr\n",
    "# !sudo apt-get install poppler-utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: unstructured in /home/darklord/miniconda3/envs/torch/lib/python3.11/site-packages (0.12.0)\n",
      "Requirement already satisfied: chardet in /home/darklord/miniconda3/envs/torch/lib/python3.11/site-packages (from unstructured) (5.2.0)\n",
      "Requirement already satisfied: filetype in /home/darklord/miniconda3/envs/torch/lib/python3.11/site-packages (from unstructured) (1.2.0)\n",
      "Requirement already satisfied: python-magic in /home/darklord/miniconda3/envs/torch/lib/python3.11/site-packages (from unstructured) (0.4.27)\n",
      "Requirement already satisfied: lxml in /home/darklord/miniconda3/envs/torch/lib/python3.11/site-packages (from unstructured) (5.1.0)\n",
      "Requirement already satisfied: nltk in /home/darklord/miniconda3/envs/torch/lib/python3.11/site-packages (from unstructured) (3.8.1)\n",
      "Requirement already satisfied: tabulate in /home/darklord/miniconda3/envs/torch/lib/python3.11/site-packages (from unstructured) (0.9.0)\n",
      "Requirement already satisfied: requests in /home/darklord/miniconda3/envs/torch/lib/python3.11/site-packages (from unstructured) (2.31.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /home/darklord/miniconda3/envs/torch/lib/python3.11/site-packages (from unstructured) (4.12.2)\n",
      "Requirement already satisfied: emoji in /home/darklord/miniconda3/envs/torch/lib/python3.11/site-packages (from unstructured) (2.9.0)\n",
      "Requirement already satisfied: dataclasses-json in /home/darklord/miniconda3/envs/torch/lib/python3.11/site-packages (from unstructured) (0.6.3)\n",
      "Requirement already satisfied: python-iso639 in /home/darklord/miniconda3/envs/torch/lib/python3.11/site-packages (from unstructured) (2024.1.2)\n",
      "Requirement already satisfied: langdetect in /home/darklord/miniconda3/envs/torch/lib/python3.11/site-packages (from unstructured) (1.0.9)\n",
      "Requirement already satisfied: numpy in /home/darklord/miniconda3/envs/torch/lib/python3.11/site-packages (from unstructured) (1.26.2)\n",
      "Requirement already satisfied: rapidfuzz in /home/darklord/miniconda3/envs/torch/lib/python3.11/site-packages (from unstructured) (3.6.1)\n",
      "Requirement already satisfied: backoff in /home/darklord/miniconda3/envs/torch/lib/python3.11/site-packages (from unstructured) (2.2.1)\n",
      "Requirement already satisfied: typing-extensions in /home/darklord/miniconda3/envs/torch/lib/python3.11/site-packages (from unstructured) (4.9.0)\n",
      "Requirement already satisfied: unstructured-client in /home/darklord/miniconda3/envs/torch/lib/python3.11/site-packages (from unstructured) (0.15.2)\n",
      "Requirement already satisfied: wrapt in /home/darklord/miniconda3/envs/torch/lib/python3.11/site-packages (from unstructured) (1.16.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/darklord/miniconda3/envs/torch/lib/python3.11/site-packages (from beautifulsoup4->unstructured) (2.5)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /home/darklord/miniconda3/envs/torch/lib/python3.11/site-packages (from dataclasses-json->unstructured) (3.20.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /home/darklord/miniconda3/envs/torch/lib/python3.11/site-packages (from dataclasses-json->unstructured) (0.9.0)\n",
      "Requirement already satisfied: six in /home/darklord/miniconda3/envs/torch/lib/python3.11/site-packages (from langdetect->unstructured) (1.16.0)\n",
      "Requirement already satisfied: click in /home/darklord/miniconda3/envs/torch/lib/python3.11/site-packages (from nltk->unstructured) (8.1.7)\n",
      "Requirement already satisfied: joblib in /home/darklord/miniconda3/envs/torch/lib/python3.11/site-packages (from nltk->unstructured) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/darklord/miniconda3/envs/torch/lib/python3.11/site-packages (from nltk->unstructured) (2023.12.25)\n",
      "Requirement already satisfied: tqdm in /home/darklord/miniconda3/envs/torch/lib/python3.11/site-packages (from nltk->unstructured) (4.66.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/darklord/miniconda3/envs/torch/lib/python3.11/site-packages (from requests->unstructured) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/darklord/miniconda3/envs/torch/lib/python3.11/site-packages (from requests->unstructured) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/darklord/miniconda3/envs/torch/lib/python3.11/site-packages (from requests->unstructured) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/darklord/miniconda3/envs/torch/lib/python3.11/site-packages (from requests->unstructured) (2023.11.17)\n",
      "Requirement already satisfied: jsonpath-python>=1.0.6 in /home/darklord/miniconda3/envs/torch/lib/python3.11/site-packages (from unstructured-client->unstructured) (1.0.6)\n",
      "Requirement already satisfied: mypy-extensions>=1.0.0 in /home/darklord/miniconda3/envs/torch/lib/python3.11/site-packages (from unstructured-client->unstructured) (1.0.0)\n",
      "Requirement already satisfied: packaging>=23.1 in /home/darklord/miniconda3/envs/torch/lib/python3.11/site-packages (from unstructured-client->unstructured) (23.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/darklord/miniconda3/envs/torch/lib/python3.11/site-packages (from unstructured-client->unstructured) (2.8.2)\n"
     ]
    }
   ],
   "source": [
    "# !pip install \"unstructured[all-docs]\" \n",
    "!pip install  unstructured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install langchain==0.1.0 langchain-community==0.0.12 langchain-core==0.1.10 \\\n",
    "# langchain-experimental==0.0.49 \\\n",
    "# langchain-google-genai==0.0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/darklord/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/darklord/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56209d8adf6d4a6fb7eeebefbc05ba5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "yolox_l0.05_quantized.onnx:   0%|          | 0.00/54.6M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from unstructured.partition.pdf import partition_pdf\n",
    "\n",
    "img_path = \"./images\"\n",
    "pdf_elemnts = partition_pdf(\n",
    "    \"./Document/llama2.pdf\",\n",
    "    chunking_strategy=\"by_title\",\n",
    "    extract_images_in_pdf=True,\n",
    "    max_characters=3000,\n",
    "    new_after_n_chars=2800,\n",
    "    combine_text_under_n_chars=2000,\n",
    "    image_output_dir_path=img_path,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Saperate text and tables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "_ = load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorize elements by type\n",
    "def categorize_elements(raw_pdf_elements):\n",
    "    \"\"\"\n",
    "    Categorize extracted elements from a PDF into tables and texts.\n",
    "    raw_pdf_elements: List of unstructured.documents.elements\n",
    "    \"\"\"\n",
    "    tables = []\n",
    "    texts = []\n",
    "    for element in raw_pdf_elements:\n",
    "        if \"unstructured.documents.elements.Table\" in str(type(element)):\n",
    "            tables.append(str(element))\n",
    "        elif \"unstructured.documents.elements.CompositeElement\" in str(type(element)):\n",
    "            texts.append(str(element))\n",
    "    return texts, tables\n",
    "\n",
    "\n",
    "texts, tables = categorize_elements(pdf_elemnts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatVertexAI\n",
    "from langchain.llms import VertexAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain_core.messages import AIMessage\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "\n",
    "# Generate summaries of text elements\n",
    "def generate_text_summaries(texts, tables, summarize_texts=False):\n",
    "    \"\"\"\n",
    "    Summarize text elements\n",
    "    texts: List of str\n",
    "    tables: List of str\n",
    "    summarize_texts: Bool to summarize texts\n",
    "    \"\"\"\n",
    "\n",
    "    # Prompt\n",
    "    prompt_text = \"\"\"You are an assistant tasked with summarizing tables and text for retrieval. \\\n",
    "    These summaries will be embedded and used to retrieve the raw text or table elements. \\\n",
    "    Give a concise summary of the table or text that is well-optimized for retrieval. Table \\\n",
    "    or text: {element} \"\"\"\n",
    "    prompt = PromptTemplate.from_template(prompt_text)\n",
    "    empty_response = RunnableLambda(\n",
    "        lambda x: AIMessage(content=\"Error processing document\")\n",
    "    )\n",
    "    # Text summary chain\n",
    "    model = VertexAI(\n",
    "        temperature=0, model_name=\"gemini-pro\", max_output_tokens=1024, to\n",
    "    ).with_fallbacks([empty_response])\n",
    "    summarize_chain = {\"element\": lambda x: x} | prompt | model | StrOutputParser()\n",
    "\n",
    "    # Initialize empty summaries\n",
    "    text_summaries = []\n",
    "    table_summaries = []\n",
    "\n",
    "    # Apply to text if texts are provided and summarization is requested\n",
    "    if texts and summarize_texts:\n",
    "        text_summaries = summarize_chain.batch(texts, {\"max_concurrency\": 1})\n",
    "    elif texts:\n",
    "        text_summaries = texts\n",
    "\n",
    "    # Apply to tables if tables are provided\n",
    "    if tables:\n",
    "        table_summaries = summarize_chain.batch(tables, {\"max_concurrency\": 1})\n",
    "\n",
    "    return text_summaries, table_summaries\n",
    "\n",
    "\n",
    "# Get text, table summaries\n",
    "text_summaries2, table_summaries = generate_text_summaries(\n",
    "    texts[9:], tables, summarize_texts=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
